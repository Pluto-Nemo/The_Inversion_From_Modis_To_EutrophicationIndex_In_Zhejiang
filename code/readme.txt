1、训练从sgd5开始采用清除了ei值大于48的数据点的Origin_clean.csv。
2、sgd6和sgd7尝试了用a*ln(x+c)+b函数拟合ei值的累积分布函数，然后对ei值进行变换使其分布情况接近于均匀分布，但精度没有得到提高而且波动变大。
3、目前最好的是基于seed=15的sgd5和sgd10任务，sgd10在sgd5的基础上将ei先除以2.71再做elu，提高了对于小值的拟合能力。
4、sgd11和sgd12尝试了新的随机6，发现模型精度并没有大幅度降低，说明在新数据Origin_clean.csv上的训练效果不再高度依赖于特殊的随机划分方式。
5、从sgd13开始，尝试更换超参数，默认的设置有：ei除以2.71，seed=15
6、sgd13到sgd19逐步提高dropout，现在drop=0.6，l1,l2=0.3的sgd19将R²_valid的上限提到了0.810785。
7、sgd22,23,24(0.6)，sgd25,26,27(1)尝试增大l1,l2正则化，虽R²基本能到0.8，sgd26甚至0.82，但后期valid和test的曲线波动剧烈。
8、sgd28,29,30尝试更低的l1,l2正则化，lambda=0.1。效果和lambda=0.3时，区别不明显。
9、干脆尝试三次不加正则化，sgd31,32,33。！train_loss降低了一个数量级，或许是之前lamda取的太大了？
10、通过将sgd10和sgd19的2015_08反演结果与实测数据对比，对于大于20的高值来说，sgd10的效果明显更好。二者对于小值拟合能力都较差，sgd19似乎好一些。

不小心把所有的log文件删掉了，记录一下重要的吧，sgd10的lr = 5e-6，sample=0.3，seed=15，d=0.3，l2=0.2
sgd19 sample=1
